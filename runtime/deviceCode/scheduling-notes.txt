** SCHEDULING PROTOCOL

The basic scheduling mechanism of MERCATOR is described in (Plano and
Buhler, 2020).  The following description extends this protocol to
accommodate signals.

A node may fire only if it is ACTIVE, is not BLOCKED, and has NO
ACTIVE CHILDREN.

When a node fires, it executes a series of *runs*. In a single run, a
node consumes zero or more data items (if present), produces any
outputs and signals that result from these, and then consumes up to
one signal if any signals are pending.  

A node's firing ends when either 
 (1) the node becomes INACTIVE 
       (informally, exhausts its input queue),
 (2) some child of the node becomes ACTIVE
       (informally, its input queue fills), or
 (3) the node becomes BLOCKED
       (on some internal resource limit other than queues)

* NODE STATUS CHANGES

An inactive node becomes active when either its data or signal queue
becomes FULL, or when its upstream neighbor explicitly sets it to
FLUSHING mode and activates it.

  - for the data queue, FULL means that there is insufficient space
    remaining for the previous node to write the maximum possible
    output from processing one run's worth of inputs.

  - for the signal queue, FULL means that there is insufficient space
    remaining for the previous node to write the maximum number of 
    signals it could produce in one run.  More specifically,
    a node is assumed to produce at most MAX_SIGNALS_PER_VEC
    signals from processing one run's worth of data and at
    most MAX_SIGNALS_PER_SIG signals from processing one signal.
    [Currently, MAX_SIGNALS_PER_VEC = 2 and MAX_SIGNALS_PER_SIG = 1;
    these constants are defined in Signal.cuh]

An active node becomes inactive when its data and signal queues
become EMPTY.  

   - for the data queue, the definition of EMPTY depends on the node's
     flushing status. If the node is flushing, EMPTY means that the
     data queue contains zero items.  If it is not flushing, EMPTY means
     that there is less than the maximum number of items the node can
     process in one run.
  
   - for the signal queue, EMPTY means there are zero signals.

Note that the signal credit protocol ensures that signals are never
issued with more credit than the number of items currently in the data
queue.  Hence, it is not possible to have a nonempty signal queue
unless there are enough data items queued to allow all those signals
to be processed.

[Rationale: why does emptiness not merely require that the signal
queue be non-FULL?  This alternative definition would be safe, in that
it would allow the upstream node to make progress.  However, if we
were to halt a node's execution with less than an input width's worth
of data items and any queued signals, acquiring more data items would
not change the fact that those queued signals must be processed with
non-full inputs' worth of data.  So there's no point in putting off
the remaining data unless the signal queue is completely empty.]

An active node determines internally if it is BLOCKED on some resource
other than its queues.  If so, it terminates its firing without
processing any further input.  The node must take action before ending
the firing to ensure that it will eventually be unblocked, and *some*
code must take responsibility for scheduling the node once it
unblocks. [Currently, blocking can only happen to enumerate nodes due
to a full parent buffer.  The buffer itself will call back to
reschedule an unblocked node if it is ready to fire.]

* BEGINNING AND END OF EXECUTION

Initially, the source is active, all other nodes are inactive, and no
node is blocked.  Hence, the source is initially fireable.

An application executes as long as some node is fireable.  When the
source discovers that no more data is available in the input stream,
it issues a flush to all downstream nodes, activates these nodes, and
inactivates itself. Once this flush reaches all sink nodes, all queues
willl be empty, so the application will terminate.


** SIGNALING

A node may raise one or more signals as part of its execution.
Signals are synchronized with data on each edge of the application
independently using a credit protocol as described in (Timcheck and
Buhler, 2020).

When a signal is pending, a node's firing may terminate without
consuming all credit available to the node (e.g., due to a downstream
queue filling.)  In this circumstance, the node's remaining credit is
stored in the signa at the head of the queue.

* HANDLING SIGNALS

A signal is consumed by calling a Node's signal handler.  The handler
looks at the signal's TAG (one of a finite set of values defined in
Signal.cuh) and dispatches it to a corresponding handler function
defined in the Node.  Handlers are *virtual* functions, so that any
subclass of a Node is able to override the generic handler.


** FLUSHING BEHAVIOR

Flushing is used to ensure that a node will not wait to consume its
pending input, even if the node would not normally be eligible to fire
due to small amounts of queued data.  A node may enter flushing status
for multiple reasons, e.g. because the end of input has been reached,
or because an enumeration node has a full parent buffer and needs to
force processing of one or more "open" parents downstream to make room
for more.

In general, flushes are associated with REGIONS, which are connected
subsets of the application graph. Each region is descended from a
single HEAD node, which is not contained in the region but does
initiate flushes for it that propagate to all nodes in the region, but
not beyond it.  Regions may NOT overlap arbitrarily; either a region R
AND its head must be completely contained in another region R', or
both must be disjoint from R'. The entire graph minus the source
constitutes a region, with the source as its head.

Restriction of flushes to particular regions is accomplished by
careful choice of region numbers.  The entire graph minus the source
is region 0.  Moreover, if region B is contained in region A, then B
has a higher region number than A. Each node is labeled with the
number of the highest-numbered region in which it is contained.

Note that a path that passes through region A, followed by
non-overlapping region B, always passes through B's head node N.  Node
N is in neither region A nor region B, and a region may not include N
while excluding region B; hence, N's region number corresponds to the
smallest region that contains both A and B, and hence is less than
that the region numbers of either A or B.

Flushes are propagated from a node to its successors according to the
following rule: a flush initiated by a node with region number R
propagates to all successors with region number >= R.  Our numbering
scheme ensures that a flush initiated by the head of region R will
reach all nodes in region R, but no further.

* IMPLEMENTATION OF FLUSH PROPAGATION

A node's FLUSHING STATUS indicates whether the node is currently
flushing.  It is equal to the *lowest-numbered region* whose flush is
currently active for that node. Because flushes do not propagate from
their own region to lower-numbered regions, a node is flushing iff its
status is <= its own region.  A node that completes a flush sets its
flushing status to a number higher than its region to indicate that
it is no longer flushing.

It is possible that a node may receive a flush for some region R while
already in flushing mode due to some other region R'.  In such a
circumstance, the node's status should be updated to the *lower* of R
and R', since the lower-numbered flush propagates to a superset of
the nodes reached by the higher-numbered flush.


** OUTLINE OF FIRING FUNCTION

PRECONDITION: When a node fires, it is ACTIVE, not BLOCKED, and has NO
ACTIVE CHILDREN.  Therefore, it either
   * has no queued signals AND >= max input size queued data items, OR
   * has >= 1 queued signal, OR
   * is in flushing mode
AND none of its children have FULL data or FULL signal queues.  Hence,
the node is safe to fire and can make progress.


* SETUP

Initially, we cache in per-thread registers
  - the initial size of the input data queue 
  - the initial size of the input signal queue
  - the stored credit (if any) from the head of the input signal queue

None of these items will be updated in global memory until the end of
firing. [FIXME: so do we need to cache them, or can we rely on L1
to do so?]

We have two variables to track the number of consumed data items and
signals.

Finally, we compute the threshold for the data queue being declared
EMPTY, according to the flushing status.

* MAIN LOOP

We iterate the run loop while neither the data queue or signal queue
is EMPTY and no successor of the node has become ACTIVE.

The loop first computes limit, the maximum number of data items that
are available to the next call to the nodeFunction.  This depends on
how many input items remain and how many credits are associated with
the next signal, if any.  If no signal or flush is pending, we also
round the limit down to a multiple of the node function's requested
width (inputSizeHint).

If limit is non-zero, the node processes some number X of items <=
limit. If there are pending signals, the number of credits is also
decremented by X.

If there are pending signals and the credit count has reached 0,
the signal handler is called to consume the next signal, and the
credit is updated to reflect the following signal (if any) in
the signal queue.

Finally, each downstream channel is checked to see if it is full
and activated if so.

If the node determines that it is blocked, the main loop should
terminate at this point rather than continuing.

* UPDATES POST-LOOP

The input data and signal queues are updated to release the consumed
items.  If the signal queue is not empty, any unused credit is stored
back to the signal at the head of the queue.

If the node's queues are now EMPTY, it is deactivated.  If it has
just completed a flush,

   - the node's flush status is propagated to its successors,
        which are activated if they propagate
   - the node's flush status is cleared
